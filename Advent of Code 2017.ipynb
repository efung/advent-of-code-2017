{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.x\n",
    "import re\n",
    "import math\n",
    "\n",
    "def Input(day):\n",
    "    \"Open this day's input file.\"\n",
    "    filename = 'inputs/{}.txt'.format(day)\n",
    "    try:\n",
    "        return open(filename)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Oops, couldn't open input\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Inverse Captcha\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The captcha requires you to review a sequence of digits (your puzzle input) and find the sum of all digits that match the next digit in the list. The list is circular, so the digit after the last digit is the first digit in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be done by reading the digits into an array, then reducing them. As a Python noob, I read that for clarity, list comprehensions are preferred over lambdas, e.g. see Guido van Rossum's [post](http://www.artima.com/weblogs/viewpost.jsp?thread=98196) from 2005. However, list comprehensions produce lists, whereas reduce produces a single output. Van Rossum concedes that `reduce()` may be used when the operator is associative, so I'm going to go ahead with `reduce()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chars_to_int_array(str):\n",
    "    \"Given a string of digits, returns them as an array of integers\"\n",
    "    return [int(ch) for ch in str]\n",
    "\n",
    "def circular_list_next_item(list, index, offset=1): \n",
    "    \"Returns the list item that is 'offset' elements away after the one given by the index; the item after the last item is the first item\"\n",
    "    return list[(index + offset) % len(list)]\n",
    "\n",
    "def inverse_captcha_1(arr):\n",
    "    \"Returns sum of digits in array that match the next digit, treating list as circular.\"\n",
    "    return reduce(lambda sum, i: sum + (arr[i] if circular_list_next_item(arr, i) == arr[i] else 0), range(len(arr)), 0)\n",
    "    \n",
    "\n",
    "assert inverse_captcha_1(chars_to_int_array(\"1122\")) == 3\n",
    "assert inverse_captcha_1(chars_to_int_array(\"1111\")) == 4\n",
    "assert inverse_captcha_1(chars_to_int_array(\"1234\")) == 0\n",
    "assert inverse_captcha_1(chars_to_int_array(\"91212129\")) == 9\n",
    "\n",
    "inverse_captcha_1(chars_to_int_array(Input(1).read().rstrip(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of considering the next digit, it wants you to consider the digit halfway around the circular list. Fortunately, your list has an even number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverse_captcha_2(arr):\n",
    "    \"Returns sum of digits in array that match the digit that is halfway around, treating list as circular.\"\n",
    "    return reduce(lambda sum, i: sum + (arr[i] if circular_list_next_item(arr, i, len(arr)//2) == arr[i] else 0), range(len(arr)), 0)\n",
    "\n",
    "assert inverse_captcha_2(chars_to_int_array(\"1212\")) == 6\n",
    "assert inverse_captcha_2(chars_to_int_array(\"1221\")) == 0\n",
    "assert inverse_captcha_2(chars_to_int_array(\"123425\")) == 4\n",
    "assert inverse_captcha_2(chars_to_int_array(\"123123\")) == 12\n",
    "assert inverse_captcha_2(chars_to_int_array(\"12131415\")) == 4\n",
    "\n",
    "inverse_captcha_2(chars_to_int_array(Input(1).read().rstrip(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "> The spreadsheet consists of rows of apparently-random numbers. To make sure the recovery process is on the right track, they need you to calculate the spreadsheet's checksum. For each row, determine the difference between the largest value and the smallest value; the checksum is the sum of all of these differences.\n",
    "\n",
    "Initially, I thought I could iterate over each row, keep track of the max and min and subtract. But it's a lot easier to just call the built-in `max` and `min`. Both methods have `O(n)` running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37923"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def line_to_int_array(line):\n",
    "    \"Given a string with whitespace-separated numbers, parse it as an array of integers\"\n",
    "    return [int(n) for n in line.split()]\n",
    "\n",
    "def lines_to_int_arrays(lines):\n",
    "    \"Given a multi-line string, each with whitespace-separated numbers, return an array of arrays of integers\"\n",
    "    return [line_to_int_array(L) for L in lines]\n",
    "    \n",
    "def max_subtract_min(L):\n",
    "    \"Return the largest element minus the smallest element\"\n",
    "    return max(L) - min(L)\n",
    "\n",
    "assert(sum([max_subtract_min(L) for L in lines_to_int_arrays(\"5 1 9 5\\n7 5 3\\n2 4 6 8\".split(\"\\n\"))])) == 18\n",
    "\n",
    "sum([max_subtract_min(L) for L in lines_to_int_arrays(Input(2).readlines())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> It sounds like the goal is to find the only two numbers in each row where one evenly divides the other - that is, where the result of the division operation is a whole number. They would like you to find those numbers on each line, divide them, and add up each line's result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had a lot of ideas of how to solve this. Clearly, we need to consider all pairs of numbers within each row. Sorting each row's numbers first, would simplify things a little, because we could always divide the smaller into the larger, by having two loops, one from each end. Or, perhaps we could apply a modulo operator, look for the single entry with zero, but that's wasteful, as we don't abort early. \n",
    "\n",
    "In the end, I preferred the simpler double for-loop, and having to compute the max/min within the inner block, since it didn't requiring any sorting, or reversing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quotient_of_divisible_elements(L):\n",
    "    \"Given a list of numbers in which there are two numbers where one exactly divides the other, return the quotient between them.\"\n",
    "    for i in range(0, len(L)-1):\n",
    "        for j in range(i+1, len(L)):\n",
    "            p = max(L[i], L[j])\n",
    "            q = min(L[i], L[j])\n",
    "            if p % q == 0:\n",
    "                return p // q\n",
    "\n",
    "assert(sum([quotient_of_divisible_elements(L) for L in lines_to_int_arrays(\"5 9 2 8\\n9 4 7 3\\n3 8 6 5\".split(\"\\n\"))])) == 9\n",
    "\n",
    "sum([quotient_of_divisible_elements(L) for L in lines_to_int_arrays(Input(2).readlines())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3\n",
    "## Part 1\n",
    "> Each square on the grid is allocated in a spiral pattern starting at a location marked 1 and then counting up while spiraling outward. For example, the first few squares are allocated like this:\n",
    "\n",
    "```\n",
    "17  16  15  14  13\n",
    "18   5   4   3  12\n",
    "19   6   1   2  11\n",
    "20   7   8   9  10\n",
    "21  22  23---> ...\n",
    "```\n",
    "> requested data must be carried back to square 1 (the location of the only access port for this memory system) by programs that can only move up, down, left, or right. They always take the shortest path: the [Manhattan Distance](https://en.wikipedia.org/wiki/Taxicab_geometry) between the location of the data and square 1.\n",
    "> How many steps are required to carry the data from the square identified in your puzzle input all the way to the access port?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought about all the different ways I could represent this spiral structure, and be able to get its grid coordinates in an efficient way. After racking my brain for a bit, I noticed a pattern in the bottom right elements of each concentric \"ring\". They were successive powers of odd numbers, e.g. `1=1*1, 9=3*3, 25=5*5`, with the number representing the side length of each ring. Also, every element in a given ring is less than or equal to that corner element (due to the counter-clockwise way the ring is constructed).\n",
    "\n",
    "With this knowledge, my idea was to figure out on which ring the puzzle input belonged to, figure out its position on the ring, then calculate the Manhattan distance to the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = int(Input(3).read().rstrip('\\n'))\n",
    "\n",
    "dim = math.ceil(math.sqrt(input))\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the input sits on the ring with bottom right corner element `559*559==312481`, and where each side has 559 numbers.  `312481 - 312051 == 430` which is less than the side length, so our element sits on the bottom row of the square.\n",
    "\n",
    "Since the bottom right corner element is the square of an odd number, the number of steps to the center is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vert_steps = dim // 2\n",
    "vert_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to figure out the horizontal distance to the center, we need to take the absolute difference between our input number and the center element in our row. The number in our ring, that is directly below the center `1` element would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312202"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_center = dim**2 - dim // 2\n",
    "row_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So then the number of horizontal steps would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horiz_steps = abs(input - row_center)\n",
    "horiz_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our final answer is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vert_steps + horiz_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> If we have a function that can tell us the (x,y) of each item, given the square's index, we could easily compute the values by filling them in sequentially, as we could easily get the neighbours from a 2D array.\n",
    "\n",
    "Do the values fit a recurrence relation?\n",
    "Could we figure out a way to map a straight 1d array and coil it?\n",
    "\n",
    "The size of each concentric \"ring\" is:\n",
    "1, 8=2*4, 16=4*4, 24=6*4\n",
    "\n",
    "\n",
    "1 R \n",
    "2 U 3 L 4 L 5 D 6 D 7 R 8 R 9 R\n",
    "10 U 11 U 12 U 13 L 14 L 15 L 16 L 17 D 18 D 19 D 20 D 21 R 22 R 23 R 24 R 25 R\n",
    "\n",
    "Make a really large array, e.g. 559x559. Start in middle. Then keep track of size of spiral we're currently filling, and then fill it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_2d(rows, cols, init_value = 0):\n",
    "    return [ [init_value] * cols for r in range(rows) ]\n",
    "\n",
    "def neighbour_sum(arr, x, y):\n",
    "    \"Return the sum of the adjacent neighbours of arr[x][y], including diagonals\"\n",
    "    rows = len(arr)\n",
    "    cols = len(arr[0])\n",
    "    \n",
    "    if x == (rows // 2) and y == (cols // 2):\n",
    "        return 1\n",
    "    \n",
    "    sum = 0\n",
    "    if (x-1 >= 0):\n",
    "        sum += arr[x-1][y]\n",
    "        if (y-1 >= 0):\n",
    "            sum += arr[x-1][y-1]\n",
    "        if (y+1 <= rows-1):\n",
    "            sum += arr[x-1][y+1]\n",
    "    if (x+1 <= cols-1):    \n",
    "        sum += arr[x+1][y]\n",
    "        if (y-1 >- 0):\n",
    "            sum += arr[x+1][y-1]\n",
    "        if (y+1 <= rows-1):\n",
    "            sum += arr[x+1][y+1]\n",
    "\n",
    "    if (y-1 >- 0):\n",
    "        sum += arr[x][y-1]\n",
    "    if (y+1 <= rows-1):\n",
    "        sum += arr[x][y+1]\n",
    "\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spiral_index_generator(dim):\n",
    "    generated = 0\n",
    "    \n",
    "    x = dim // 2\n",
    "    y = dim // 2\n",
    "    yield x, y\n",
    "\n",
    "    for spiral_len in range(3, dim+1, 2):\n",
    "        # Each time we start new ring, we are one up\n",
    "        # from bottom right corner\n",
    "        dir_steps = 1\n",
    "        x += 1\n",
    "        for curdir in ['U', 'L', 'D', 'R']:\n",
    "            while dir_steps < spiral_len-1:\n",
    "                yield x, y   \n",
    "\n",
    "                if curdir == 'U':\n",
    "                    y -= 1\n",
    "                elif curdir == 'L':\n",
    "                    x -= 1\n",
    "                elif curdir == 'D':\n",
    "                    y += 1\n",
    "                elif curdir == 'R':\n",
    "                    x += 1\n",
    "                dir_steps += 1\n",
    "                \n",
    "            dir_steps = 0\n",
    "        yield x, y\n",
    "\n",
    "def stress_test(dim, sentinel):\n",
    "    arr = initialize_2d(dim, dim)\n",
    "    for x, y, in spiral_index_generator(dim):\n",
    "        arr[x][y] = neighbour_sum(arr, x, y)\n",
    "        if arr[x][y] > sentinel:\n",
    "            return arr[x][y]\n",
    "\n",
    "stress_test(15, 312051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4\n",
    "## Part 1\n",
    "> A passphrase consists of a series of words (lowercase letters) separated by spaces. To ensure security, a valid passphrase must contain no duplicate words. How many passphrases are valid?\n",
    "\n",
    "The approach I thought of immediately is to maintain a map from the word to a count of the number of times the word appears on each line. But it's simpler to just put all the words in a set, which automatically removes duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def line_to_string_array(line):\n",
    "    \"Given a string with whitespace-separated words, parse it as an array of strings\"\n",
    "    return [n for n in line.split()]\n",
    "\n",
    "def lines_to_string_arrays(lines):\n",
    "    \"Given a multi-line string, each with whitespace-separated words, return an array of arrays of words\"\n",
    "    return [line_to_string_array(L) for L in lines]\n",
    "\n",
    "def duplicate_words(arr):\n",
    "    \"Given an array of words, return true if the array contains duplicate words, false otherwise\"\n",
    "    return len(arr) != len(set(arr))\n",
    "\n",
    "assert(duplicate_words(line_to_string_array(\"aa bb cc dd ee\"))) == False\n",
    "assert(duplicate_words(line_to_string_array(\"aa bb cc dd aa\"))) == True\n",
    "assert(duplicate_words(line_to_string_array(\"aa bb cc dd aaa\"))) == False\n",
    "\n",
    "valid_lines = [duplicate_words(arr) for arr in lines_to_string_arrays(Input(4).readlines())]\n",
    "\n",
    "sum([(1 if not valid else 0) for valid in valid_lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4\n",
    "## Part 2\n",
    "> …a valid passphrase must contain no two words that are anagrams of each other - that is, a passphrase is invalid if any word's letters can be rearranged to form any other word in the passphrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key insight here is that to detect an anagram, you can employ a similar technique to look for duplicate words, but sorting the letters in each word first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def has_anagram(arr):\n",
    "    \"Given an array of strings, return true if any of the words is an anagram of any other word; false, otherwise.\"\n",
    "    dict = { ''.join(sorted([c for c in word])): 1 for word in arr }\n",
    "    return len(dict.keys()) != len(arr)\n",
    "\n",
    "assert(has_anagram(line_to_string_array(\"abcde fghij\"))) == False\n",
    "assert(has_anagram(line_to_string_array(\"abcde xyz ecdab\"))) == True\n",
    "assert(has_anagram(line_to_string_array(\"a ab abc abd abf abj\"))) == False\n",
    "assert(has_anagram(line_to_string_array(\"iiii oiii ooii oooi oooo\"))) == False\n",
    "assert(has_anagram(line_to_string_array(\"oiii ioii iioi iiio\"))) == True\n",
    "\n",
    "check = [has_anagram(line) for line in lines_to_string_arrays(Input(4).readlines())]\n",
    "\n",
    "sum(0 if has_anagram else 1 for has_anagram in check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5\n",
    "## Part 1\n",
    "> The message includes a list of the offsets for each jump. Jumps are relative: -1 moves to the previous instruction, and 2 skips the next one. Start at the first instruction in the list. The goal is to follow the jumps until one leads outside the list.\n",
    "\n",
    "> In addition, these instructions are a little strange; after each jump, the offset of that instruction increases by 1. So, if you come across an offset of 3, you would move three instructions forward, but change it to a 4 for the next time it is encountered.\n",
    "\n",
    "This seems fairly straightforward: read the data into a mutable array, and just update as we traverse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_to_int_array(input):\n",
    "    return [int(e.strip()) for e in input.split()]\n",
    "\n",
    "def jump_maze_1(arr):\n",
    "    \"Given an array of integers representing jumps, follow the Part 1 rules and return the number of steps before we reach an index outside of the array dimension.\"\n",
    "    steps = 0\n",
    "    pos = 0\n",
    "    while True:\n",
    "        try:\n",
    "            jump = arr[pos]\n",
    "            arr[pos] += 1\n",
    "            pos += jump\n",
    "            steps += 1\n",
    "        except IndexError:\n",
    "            return steps\n",
    "\n",
    "assert(jump_maze_1(lines_to_int_array(\"0\\n 3\\n 0 \\n1\\n -3\"))) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342669"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jump_maze_1(lines_to_int_array(Input(5).read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> Now, the jumps are even stranger: after each jump, if the offset was three or more, instead decrease it by 1. Otherwise, increase it by 1 as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_maze_2(arr):\n",
    "    \"Given an array of integers representing jumps, follow the Part 2 rules and return the number of steps before we reach an index outside of the array dimension.\"\n",
    "    steps = 0\n",
    "    pos = 0\n",
    "    while True:\n",
    "        try:\n",
    "            jump = arr[pos]\n",
    "            offset = -1 if jump >= 3 else 1\n",
    "            arr[pos] += offset\n",
    "            pos += jump\n",
    "            steps += 1\n",
    "        except IndexError:\n",
    "            return steps\n",
    "assert(jump_maze_2(lines_to_int_array(\"0\\n 3\\n 0 \\n1\\n -3\"))) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25136209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jump_maze_2(lines_to_int_array(Input(5).read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6\n",
    "## Part 1\n",
    "> The reallocation routine operates in cycles. In each cycle, it finds the memory bank with the most blocks (ties won by the lowest-numbered memory bank) and redistributes those blocks among the banks. To do this, it removes all of the blocks from the selected bank, then moves to the next (by index) memory bank and inserts one of the blocks. It continues doing this until it runs out of blocks; if it reaches the last memory bank, it wraps around to the first one.\n",
    "\n",
    "> The debugger would like to know how many redistributions can be done before a blocks-in-banks configuration is produced that has been seen before.\n",
    "\n",
    "The obvious solution is to just follow the description and keep track of the index of the current position in the memory bank, a counter for how many redistribution cycles have been performed, and a map of the states seen. To do a redistribution, find `max(array)` and use `array.index(max(array))` to know where to start redistribution.\n",
    "\n",
    "Improving on the obvious solution, instead of adding one to each bank during redistribution, try to update each bank with all the blocks that it needs, by dividing the selected block value by the size of the array. There's a bit of adjustment to account for the remainder if the division is not exact.\n",
    "\n",
    "## Part 2\n",
    "> starting from a state that has already been seen, how many block redistribution cycles must be performed before that same state is seen again?\n",
    "\n",
    "This can be done by extending the redistribution implementation, and storing the cycle number where a state was first seen. When we see it again, we subtract the current cycle number from the cycle when it was first seen, to determine the size of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redistribute(arr):\n",
    "    alen = len(arr)\n",
    "    pos = 0\n",
    "    cycles = 0\n",
    "    states = {}\n",
    "    while True:\n",
    "        most = max(arr)\n",
    "        pos = arr.index(most) # finds lowest index\n",
    "        arr[pos] = 0 # Remove for redistribution\n",
    "        pos += 1\n",
    "        while most > 0:\n",
    "            arr[pos % alen] += 1\n",
    "            most -= 1\n",
    "            pos += 1\n",
    "        cycles += 1\n",
    "        #print(tuple(arr))\n",
    "        if (tuple(arr) in states):\n",
    "            first_repeat_state = tuple(arr)\n",
    "            break\n",
    "        states[tuple(arr)] = cycles # Records on which cycle this state was first seen\n",
    "    return cycles, (first_repeat_state, states[first_repeat_state])\n",
    "\n",
    "cycles, (state, cycle_first_seen) = redistribute([0,2,7,0])\n",
    "assert(cycles) == 5\n",
    "assert(cycles - cycle_first_seen) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3156"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycles, (first_repeat_state, cycle_first_seen) = redistribute(line_to_int_array(Input(6).read()))\n",
    "cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycles - cycle_first_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7\n",
    "## Part 1\n",
    "\n",
    "> One program at the bottom supports the entire tower. It's holding a large disc, and on the disc are balanced several more sub-towers. At the bottom of these sub-towers, standing on the bottom disc, are other programs, each holding their own disc, and so on. At the very tops of these sub-sub-sub-...-towers, many programs stand simply keeping the disc below them balanced but with no disc of their own.\n",
    "> You ask each program to yell out their name, their weight, and (if they're holding a disc) the names of the programs immediately above them balancing on that disc. \n",
    "> What is the name of the bottom program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_bottom_program(lines):\n",
    "    parentmap = {}\n",
    "    for line in lines:\n",
    "        m = re.match(r\"(\\w+) \\((\\d+)\\)( -> (.*))?\", line)\n",
    "        # Ignore leaf nodes, they don't help in finding lowest\n",
    "        if m != None and m.group(4) != None:\n",
    "            parentname = m.group(1)\n",
    "            children = [e.strip() for e in m.group(4).split(',')]\n",
    "            for childname in children:\n",
    "                parentmap[childname] = parentname\n",
    "    \n",
    "    # Pick arbitrary node, traverse up to parent\n",
    "    visit = list(parentmap.keys())[0]\n",
    "    while visit in parentmap:\n",
    "        visit = parentmap[visit]\n",
    "    return visit\n",
    "\n",
    "test_data = \"\"\"\n",
    "pbga (66)\n",
    "xhth (57)\n",
    "ebii (61)\n",
    "havc (66)\n",
    "ktlj (57)\n",
    "fwft (72) -> ktlj, cntj, xhth\n",
    "qoyq (66)\n",
    "padx (45) -> pbga, havc, qoyq\n",
    "tknk (41) -> ugml, padx, fwft\n",
    "jptl (61)\n",
    "ugml (68) -> gyxo, ebii, jptl\n",
    "gyxo (61)\n",
    "cntj (57)\n",
    "\"\"\"\n",
    "assert(find_bottom_program(test_data.split('\\n'))) == 'tknk'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cyrupz'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_bottom_program(Input(7).readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> For any program holding a disc, each program standing on that disc forms a sub-tower. Each of those sub-towers are supposed to be the same weight, or the disc itself isn't balanced. The weight of a tower is the sum of the weights of the programs in that tower.\n",
    "> Given that exactly one program is the wrong weight, what would its weight need to be to balance the entire tower?\n",
    "\n",
    "Store all the weights of each disc in one map. Track each disc's children in another map. Define a recursive function to compute weight of program on a disc: if leaf node (no children), weight is own weight. If children, then own weight plus sum of childrens' weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tower_structures(lines):\n",
    "    weight_map = {}\n",
    "    child_map = {}\n",
    "    for line in lines:\n",
    "        m = re.match(r\"(\\w+) \\((\\d+)\\)( -> (.*))?\", line)\n",
    "        name = m.group(1)\n",
    "        weight = int(m.group(2))\n",
    "        weight_map[name] = weight\n",
    "        \n",
    "        if m.group(4) != None:\n",
    "            child_map[name] = [e.strip() for e in m.group(4).split(',')]\n",
    "    return weight_map, child_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_weight(name, weight_map, child_map):\n",
    "    self = weight_map[name]\n",
    "    children = (sum([program_weight(child, weight_map, child_map) for child in child_map[name]])) if name in child_map else 0\n",
    "    return self + children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_map, child_map = initialize_tower_structures( Input(7).readlines() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from root (found in previous part), we check weights of children and recurse on whichever has a different weight than the others. Once we have found the disc that is balanced, we look at its peers to determine what weight needs to be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def find_black_sheep(L, common):\n",
    "    \"Given an array of items that are all assumed to be the given value 'common', return the index of the odd one out. If all elements are the same, raise StopIteration\"\n",
    "    return next(i for i, v in enumerate(L) if v != common)\n",
    "\n",
    "def find_weight_adjustment(root_name, weight_map, child_map):\n",
    "    print(root_name)\n",
    "    child_weights = [program_weight(child, weight_map, child_map) for child in child_map[root_name]]\n",
    "    print(\"\\t{}\".format(child_weights))\n",
    "    try:\n",
    "        common = collections.Counter(child_weights).most_common()[0][0]\n",
    "        index = find_black_sheep(child_weights, common)\n",
    "        next_root = child_map[root_name][index]\n",
    "        adjust = find_weight_adjustment(next_root, weight_map, child_map)\n",
    "        if adjust == None:\n",
    "            next_root_weight = weight_map[next_root]\n",
    "            black_sheep = child_weights[index]\n",
    "            print(\"weight[{}]={} + ({} - {})\".format(next_root, next_root_weight, common, black_sheep))\n",
    "            return next_root_weight + (common - black_sheep)\n",
    "        else:\n",
    "            return adjust\n",
    "    except StopIteration:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyrupz\n",
      "\t[119424, 119424, 119424, 119424, 119424, 119424, 119432]\n",
      "qjvtm\n",
      "\t[12146, 12154, 12146]\n",
      "boropxd\n",
      "\t[1123, 1123, 1123, 1123, 1131, 1123, 1123]\n",
      "cwwwj\n",
      "\t[310, 310, 310]\n",
      "weight[cwwwj]=201 + (1123 - 1131)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_weight_adjustment('cyrupz', weight_map, child_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8\n",
    "## Part 1\n",
    "> Each instruction consists of several parts: the register to modify, whether to increase or decrease that register's value, the amount by which to increase or decrease it, and a condition. If the condition fails, skip the instruction without modifying the register. The registers all start at 0. The instructions look like this:\n",
    "```\n",
    "b inc 5 if a > 1\n",
    "a inc 1 if b < 5\n",
    "c dec -10 if a >= 1\n",
    "c inc -20 if c == 10\n",
    "```\n",
    "\n",
    "Keep a map of all registers. Parse each instruction line, check the condition, and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4066"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def parse_instruction(line):\n",
    "    m = re.match(r\"(\\w+) (inc|dec) (-?\\d+) if (\\w+) (.*) (-?\\d+)\", line)\n",
    "    return m.groups()\n",
    "\n",
    "def test_reg_condition(regs, test_reg, oper, str_value):\n",
    "    \"Return the result of evaluating a register predicate.\"\n",
    "    val = int(str_value)\n",
    "    if oper == '>':\n",
    "        return regs[test_reg] > val\n",
    "    elif oper == '<':\n",
    "        return regs[test_reg] < val\n",
    "    elif oper == '>=':\n",
    "        return regs[test_reg] >= val\n",
    "    elif oper == '<=':\n",
    "        return regs[test_reg] <= val\n",
    "    elif oper == '==':\n",
    "        return regs[test_reg] == val\n",
    "    elif oper == '!=':\n",
    "        return regs[test_reg] != val\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "def compute_result(lines, regs):\n",
    "    \"Execute the program given in 'lines', updating register values in 'regs', and returning the largest value ever stored in any register.\"\n",
    "    highwater = 0\n",
    "    for line in lines:\n",
    "        reg, inc_oper, val, test_reg, test_oper, test_value = parse_instruction(line)\n",
    "        if test_reg_condition(regs, test_reg, test_oper, test_value):\n",
    "            value = 0\n",
    "            if inc_oper == 'inc':\n",
    "                value = int(val)\n",
    "            elif inc_oper == 'dec':\n",
    "                value = -int(val)\n",
    "            regs[reg] += value\n",
    "            if regs[reg] > highwater:\n",
    "                highwater = regs[reg]\n",
    "    return highwater\n",
    "\n",
    "regs = defaultdict(lambda: 0)\n",
    "\n",
    "test = \"\"\"b inc 5 if a > 1\n",
    "a inc 1 if b < 5\n",
    "c dec -10 if a >= 1\n",
    "c inc -20 if c == 10\"\"\"\n",
    "highwater = compute_result(test.split('\\n'), regs)\n",
    "assert(max(regs.values())) == 1\n",
    "assert(highwater) == 10\n",
    "\n",
    "regs = defaultdict(lambda: 0)\n",
    "compute_result(Input(8).readlines(), regs)\n",
    "max(regs.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> the CPU also needs to know the highest value held in any register during this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4829"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regs = defaultdict(lambda: 0)\n",
    "compute_result(Input(8).readlines(), regs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 9\n",
    "## Part 1\n",
    "> The characters represent groups - sequences that begin with { and end with }. Within a group, there are zero or more other things, separated by commas: either another group or garbage. Since groups can contain other groups, a } only closes the most-recently-opened unclosed group - that is, they are nestable. Your puzzle input represents a single, large group which itself contains many smaller ones.\n",
    "\n",
    "> Sometimes, instead of a group, you will find garbage. Garbage begins with < and ends with >. Between those angle brackets, almost any character can appear, including { and }. Within garbage, < has no special meaning… Inside garbage, any character that comes after ! should be ignored, including <, >, and even another !.\n",
    "\n",
    "A simple state machine can be used for this. Whenever we encounter a group, we can call a \"parse group\" function recursively. We pass in the score from the parent group into the child group. Each parse group method returns the score for itself, the parent group adds it to its own score. We only need to process the stream a character at a time, so we can use a file/stream abstraction that keeps track of the current position.\n",
    "\n",
    "## Part 2\n",
    "Since we already wrote a method to parse garbage, extending it to keep track of the count is pretty simple. We return a tuple of the score and garbage length from the parse group method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "def parse_garbage(file):\n",
    "    \"Given a stream pointing at the character right after the start of the garbage start character, continue reading until the garbage block is completely read. The stream will be left at one character after the end garbage character. Return the number of garbage characters, not including the start/end chars nor cancelled chars nor the cancelling chars.\"\n",
    "    count = 0\n",
    "    char = read_char(file)\n",
    "    while char == '!' and char != '':\n",
    "        read_char(file)\n",
    "        char = read_char(file)\n",
    "    while char != '>' and char != '':\n",
    "        count += 1\n",
    "        char = read_char(file)\n",
    "        while char == '!' and char != '':\n",
    "            read_char(file)\n",
    "            char = read_char(file)\n",
    "    return count\n",
    "    \n",
    "def parse_group(own_score, file):\n",
    "    \"Given a file object, read from the current position until we see an ending group character. Return the group score.\"\n",
    "    garbage_count = 0\n",
    "    score = own_score\n",
    "    char = read_char(file)\n",
    "    while char != '}' and char != '':\n",
    "        if char == '<':\n",
    "            garbage_count += parse_garbage(file)\n",
    "        elif char == '{':\n",
    "            child_group_score, child_garbage_count = parse_group(own_score+1, file)\n",
    "            score += child_group_score\n",
    "            garbage_count += child_garbage_count\n",
    "         \n",
    "        char = read_char(file)\n",
    "\n",
    "    return score, garbage_count\n",
    "\n",
    "def read_char(file):\n",
    "    char = file.read(1)\n",
    "    return char\n",
    "\n",
    "assert(parse_group(0, StringIO('{}'))[0]) == 1\n",
    "assert(parse_group(0, StringIO('{{{}}}'))[0]) == 6\n",
    "assert(parse_group(0, StringIO('{{},{}}'))[0]) == 5\n",
    "assert(parse_group(0, StringIO('{{{},{},{{}}}}'))[0]) == 16\n",
    "assert(parse_group(0, StringIO('{<a>,<a>,<a>,<a>}'))[0]) == 1\n",
    "assert(parse_group(0, StringIO('{{<ab>},{<ab>},{<ab>},{<ab>}}'))[0]) == 9\n",
    "assert(parse_group(0, StringIO('{{<!!>},{<!!>},{<!!>},{<!!>}}'))[0]) == 9\n",
    "assert(parse_group(0, StringIO('{{<a!>},{<a!>},{<a!>},{<ab>}}'))[0]) == 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12803, 6425)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_group(0, Input(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 10\n",
    "## Part 1\n",
    "> To achieve this, begin with a list of numbers from 0 to 255, a current position which begins at 0 (the first element in the list), a skip size (which starts at 0), and a sequence of lengths (your puzzle input). Then, for each length:\n",
    "\n",
    "- Reverse the order of that length of elements in the list, starting with the element at the current position.\n",
    "- Move the current position forward by that length plus the skip size.\n",
    "- Increase the skip size by one.\n",
    "> The list is circular; if the current position and the length try to reverse elements beyond the end of the list, the operation reverses using as many extra elements as it needs from the front of the list. If the current position moves past the end of the list, it wraps around to the front. Lengths larger than the size of the list are invalid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_line_to_int_array(line):\n",
    "    \"Given a string with comma-separated numbers, parse it as an array of integers\"\n",
    "    return [int(n) for n in line.split(',')]\n",
    "\n",
    "def circular_list_reverse(arr, pos, length):\n",
    "    \"Given a circular array, and a starting position, reverse the elements from pos to pos+length-1\"\n",
    "    arrlen = len(arr)\n",
    "    for x in range(0, length // 2):\n",
    "        i = (pos + x) % arrlen\n",
    "        j = (pos + length - 1 -x) % arrlen\n",
    "        arr[i], arr[j] = arr[j], arr[i]\n",
    "        \n",
    "def knot_hash(input_lengths, arr, rounds=1):\n",
    "    skip = 0\n",
    "    pos = 0\n",
    "    for r in range(0,rounds):\n",
    "        for length in input_lengths:\n",
    "            circular_list_reverse(arr, pos, length)\n",
    "            pos += length + skip\n",
    "            skip += 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(knot_hash([3,4,1,5], list(range(0, 5)))) == [3, 4, 2, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38415"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = knot_hash(csv_line_to_int_array(Input(10).read()), list(range(0, 256)))\n",
    "output[0] * output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> First, from now on, your input should be taken not as a list of numbers, but as a string of bytes instead. Unless otherwise specified, convert characters to bytes using their ASCII codes. This will allow you to handle arbitrary ASCII strings, and it also ensures that your input lengths are never larger than 255.\n",
    "\n",
    "> Once you have determined the sequence of lengths to use, add the following lengths to the end of the sequence: 17, 31, 73, 47, 23.\n",
    "\n",
    "> Second, instead of merely running one round like you did above, run a total of 64 rounds, using the same length sequence in each round. The current position and skip size should be preserved between rounds. \n",
    "\n",
    "> Once the rounds are complete, you will be left with the numbers from 0 to 255 in some order, called the sparse hash. Your next task is to reduce these to a list of only 16 numbers called the dense hash. To do this, use numeric bitwise XOR to combine each consecutive block of 16 numbers in the sparse hash (there are 16 such blocks in a list of 256 numbers). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note about Python is the difference between `list.append()` which mutates the list by adding an object to the end, `list.extend()` which mutates a list by extending it with an iterable, and `+` which is an overload which is like `extend` but creates a new list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_ascii_bytes(str):\n",
    "    \"Returns a list with the ASCII numeric codes of each character of the input.\"\n",
    "    return [ord(c) for c in str]\n",
    "\n",
    "def preprocess_p2(arr):\n",
    "    \"Return a new list that is the extension of the given list with some fixed values.\"\n",
    "    return arr + [17, 31, 73, 47, 23]\n",
    "\n",
    "assert(preprocess_p2(input_to_ascii_bytes(\"1,2,3\"))) == [49,44,50,44,51,17, 31, 73, 47, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_list(arr):\n",
    "    \"Returns the bitwise XOR of the elements of the list.\"\n",
    "    return reduce(lambda xor, i: xor ^ i, arr)\n",
    "assert(xor_list([65, 27, 9, 1, 4, 3, 40, 50, 91, 7, 6, 0, 2, 5, 68, 22])) == 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_hash(sparse):\n",
    "    \"Return the bitwise XOR of groups of 16 elements from sparse, returning a list of len(sparse)/16 elements\"\n",
    "    return [xor_list(range) for range in [sparse[a:a+16] for a in range(0, len(sparse), 16)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's `hex()` method returns a value prefixed with `0x`. Using a format string allows us to specify padding with leading zero, number of digits and conversion type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_knot_hash(input):\n",
    "    lengths = preprocess_p2(input_to_ascii_bytes(input))\n",
    "    sparse_hash = knot_hash(lengths, list(range(0, 256)), 64)\n",
    "    dense = dense_hash(sparse_hash)                \n",
    "    return ''.join([\"%0.2x\" % num for num in dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(full_knot_hash(\"\")) == \"a2582a3a0e66e6e86e3812dcb672a272\"\n",
    "assert(full_knot_hash(\"AoC 2017\")) == \"33efeb34ea91902bb2f59c9920caa6cd\"\n",
    "assert(full_knot_hash(\"1,2,3\")) == \"3efbe78a8d82f29979031a4aa0b16a9d\"\n",
    "assert(full_knot_hash(\"1,2,4\")) == \"63960835bcdc130f0b66d7ff4f6a5a8e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9de8846431eef262be78f590e39a4848'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_knot_hash(Input(10).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 11\n",
    "## Part 1\n",
    "> The hexagons (\"hexes\") in this grid are aligned such that adjacent hexes can be found to the north, northeast, southeast, south, southwest, and northwest. You have the path the child process took. Starting where he started, you need to determine the fewest number of steps required to reach him\n",
    "\n",
    "This one I needed help with representation and algorithms. Fortunately, Red Blog Games has a [comprehensive guide](https://www.redblobgames.com/grids/hexagons/) on hexagonal grids. I decided to use the cube coordinate system as that gave a simple algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_grid_distance(a, b):\n",
    "    \"Return the distance between two points as cube coordinates on a hex grid.\"\n",
    "    return (abs(a[0] - b[0]) + abs(a[1] - b[1]) + abs(a[2] - b[2])) / 2\n",
    "\n",
    "def walk(steps):\n",
    "    \"Given a list of steps from the set of strings: [nw, n, ne, sw, s, se], map each direction using cube coordinates, and return the resulting hex grid as a cube coordinate.\"\n",
    "    pos = (0,0,0) # (x,y,z)\n",
    "    max_dist = 0\n",
    "    for step in steps:\n",
    "        if step == 'n':\n",
    "            pos = (pos[0]+1, pos[1], pos[2]-1)\n",
    "        elif step == 'nw':\n",
    "            pos = (pos[0], pos[1]+1, pos[2]-1)\n",
    "        elif step == 'ne':\n",
    "            pos = (pos[0]+1, pos[1]-1, pos[2])\n",
    "        elif step == 's':\n",
    "            pos = (pos[0]-1, pos[1], pos[2]+1)\n",
    "        elif step == 'sw':\n",
    "            pos = (pos[0]-1, pos[1]+1, pos[2])\n",
    "        elif step == 'se':\n",
    "            pos = (pos[0], pos[1]-1, pos[2]+1)\n",
    "        dist = hex_grid_distance((0,0,0), pos)\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "    return pos, max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest, max_dist = walk(Input(11).read().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_grid_distance((0,0,0), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1435.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 12\n",
    "## Part 1\n",
    "> You walk through the village and record the ID of each program and the IDs with which it can communicate directly (your puzzle input). Each program has one or more programs with which it can communicate, and these pipes are bidirectional; if 8 says it can communicate with 11, then 11 will say it can communicate with 8.\n",
    "\n",
    "> You need to figure out how many programs are in the group that contains program ID 0.\n",
    "\n",
    "This input shows the neighbours of every program. I initially searched for information about spanning trees and connected graphs, but quickly realized that the input is just an [adjacency list](https://en.wikipedia.org/wiki/Adjacency_list). A simple way to solve this part would be to just recursively add nodes as we traverse the children of ID 0. I peeked at the pseudocode in one of the answers in this [Stack Overflow post](https://stackoverflow.com/questions/21864857/find-all-connected-nodes-in-adjacency-list)! However, the examples use a directed graph, whereas ours is bidirectional, so we need to ensure we don't recurse infinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(program_id, adjacency, g):\n",
    "    \"Compute the connected nodes of the given ID in the adjacency list, using a running set to keep track. Return set of nodes.\"\n",
    "    if program_id not in g:\n",
    "        g.add(program_id)\n",
    "    for n in adjacency[program_id]:\n",
    "        if n not in g:\n",
    "            g.add(n)\n",
    "            get_group(n, adjacency, g)\n",
    "    return g\n",
    "    \n",
    "def parse_communication_list(lines):\n",
    "    \"Build a map of program ID communication partners, indexed by program ID. That is, the adjacency list of each program ID.\"\n",
    "    adjacency = defaultdict(lambda: [])\n",
    "    for entry in lines:\n",
    "        groups = re.match(r\"(\\d+) <-> (.*)\", entry)\n",
    "        program_id = int(groups[1])\n",
    "        neighbors = [int(x) for x in groups[2].split(',')]\n",
    "        adjacency[program_id] = neighbors\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"0 <-> 2\n",
    "1 <-> 1\n",
    "2 <-> 0, 3, 4\n",
    "3 <-> 2, 4\n",
    "4 <-> 2, 3, 6\n",
    "5 <-> 6\n",
    "6 <-> 4, 5\"\"\"\n",
    "adj = parse_communication_list(test.split('\\n'))\n",
    "assert(get_group(0, adj, set())) == set([0,2,3,4,6,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = parse_communication_list(Input(12).readlines())\n",
    "len(get_group(0, adj, set()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> A group is a collection of programs that can all communicate via pipes either directly or indirectly. The programs you identified just a moment ago are all part of the same group. Now, they would like you to determine the total number of groups.\n",
    "\n",
    "A straightforward way is to maintain a set of program IDs who are not part of a group, initially, the entire group. While this set is not empty, pick one at random, compute the connected group, and remove those elements from the larger group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = parse_communication_list(Input(12).readlines())\n",
    "all_programs = set(adj.keys())\n",
    "total_groups = 0\n",
    "while len(all_programs) > 0:\n",
    "    group = get_group(all_programs.pop(), adj, set())\n",
    "    total_groups += 1\n",
    "    all_programs = all_programs.difference(group)\n",
    "total_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 13\n",
    "## Part 1\n",
    "> By studying the firewall briefly, you are able to record (in your puzzle input) the **depth** of each layer and the **range** of the scanning area for the scanner within it, written as depth: range. Each layer has a thickness of exactly 1. A layer at depth 0 begins immediately inside the firewall; a layer at depth 1 would start immediately after that.\n",
    "\n",
    "> Visually, it might look like this:\n",
    "```\n",
    " 0   1   2   3   4   5   6\n",
    "[ ] [ ] ... ... [ ] ... [ ]\n",
    "[ ] [ ]         [ ]     [ ]\n",
    "[ ]             [ ]     [ ]\n",
    "                [ ]     [ ]\n",
    "```\n",
    "> Within each layer, a security scanner moves back and forth within its range. Each security scanner starts at the top and moves down until it reaches the bottom, then moves up until it reaches the top, and repeats. A security scanner takes **one picosecond** to move one step. \n",
    "> Your plan is to hitch a ride on a packet about to move through the firewall. The packet will travel along the top of each layer, and it moves at **one layer per picosecond**. Each picosecond, the packet moves one layer forward (its first move takes it into layer 0), and then the scanners move one step. If there is a scanner at the top of the layer **as your packet enters it**, you are **caught**. (If a scanner moves into the top of its layer while you are there, you are not caught: it doesn't have time to notice you before you leave.) \n",
    "> The **severity** of getting caught on a layer is equal to its **depth** multiplied by its **range**. (Ignore layers in which you do not get caught.)\n",
    "\n",
    "Note that each scanner's position is independent of the others, and the only information we need to predict where a scanner will be at a given instant in time is its depth and range. Since we only care about whether we are caught or not, it suffices to figure out how many of the scanners will be at the top when we enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanner_position(_d, _r, _t):\n",
    "    \"Given the specified scanner, with an initial position of 0 (the top) at time 0, return the scanner's position (a value between 0 and _range-1) at the *beginning* of the picosecond given by _t.\"\n",
    "\n",
    "    # Period is how many time units before scanner positions repeat. The scanner goes backward\n",
    "    # when it reaches the end, without repeating the last element, nor the first. So the\n",
    "    # period is _r + _r - 2.\n",
    "    p = (_r - 1) * 2\n",
    "\n",
    "    # Consider the indices mod the period. So the indices would be [0, p-1] and\n",
    "    # _t % p gives the correct scanner position for the first _r-1 times. For the\n",
    "    # remaining ones, the position gets smaller, the further you are from _r-1.\n",
    "    tmodp = _t % p\n",
    "    return tmodp if tmodp < _r else p - tmodp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the penalty, we just need to get all time instances when the scanner is in the first position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def severity(_d, _r):\n",
    "    return _d * _r\n",
    "\n",
    "def predict_all_future_positions(firewall, t=0):\n",
    "    \"Generate an array of the position of each scanner, at the instant when the packet enters that layer, starting at beginning of given time.\"\n",
    "    return [scanner_position(d, firewall[d], t + d) if d in firewall else None for d in range(0, max(firewall.keys())+1)]\n",
    "\n",
    "def snapshot_positions(firewall, t=0):\n",
    "    \"Generate an array of the position of each scanner, at the beginning of an instant in time.\"\n",
    "    return [scanner_position(d, firewall[d], t) if d in firewall else None for d in range(0, max(firewall.keys())+1)]\n",
    "\n",
    "def trip_severity(firewall, delay=0):\n",
    "    \"Calculate the total trip severity, the sum of the severities at each layer.\"\n",
    "    pos = predict_all_future_positions(firewall, delay)\n",
    "    return sum([severity(ind, firewall[ind]) if s != None and s == 0 else 0 for ind, s in enumerate(pos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {0: 3,1: 2,4: 4,6: 4}\n",
    "assert(trip_severity(test)) == 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1904"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_packet_scanner(lines):\n",
    "    \"Parse each line as a scanner definition, and return a dictionary.\"\n",
    "    d = {}\n",
    "    for line in lines:\n",
    "        g = re.match(r\"(\\d+): (\\d+)\", line)\n",
    "        d[int(g[1])] = int(g[2])\n",
    "    return d\n",
    "\n",
    "firewall = read_packet_scanner(Input(13).readlines())\n",
    "trip_severity(firewall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> Now, you need to pass through the firewall without being caught - easier said than done.\n",
    "\n",
    "> You can't control the speed of the packet, but you can delay it any number of picoseconds. For each picosecond you delay the packet before beginning your trip, all security scanners move one step. You're not in the firewall during this time; you don't enter layer 0 until you stop delaying the packet.\n",
    "\n",
    "> Because all smaller delays would get you caught, the fewest number of picoseconds you would need to delay to get through safely is 10.\n",
    "\n",
    "> What is the fewest number of picoseconds that you need to delay the packet to pass through the firewall without being caught?\n",
    "\n",
    "I initially tried iterating over delay values, and checking their trip severities but my solution to the example and the full input were failing. After a bit debugging, I realized that a trip severity of **0** does not mean you don't get caught, since the penalty for getting caught in the first layer is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_caught(firewall, t=0):\n",
    "    \"Return boolean indicating whether you would get caught traversing the firewall beginning at the specified time.\"\n",
    "    return any(p == 0 for p in predict_all_future_positions(firewall, t))\n",
    "    \n",
    "def find_delay_without_caught(firewall):\n",
    "    delay = 0\n",
    "    caught = is_caught(firewall, delay)\n",
    "    while caught:\n",
    "        delay += 1\n",
    "        caught = is_caught(firewall, delay)\n",
    "    return delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(find_delay_without_caught(test)) == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following takes a long time (~2 minutes) to get the right answer (3833504)\n",
    "#find_delay_without_caught(firewall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential speedups for above: there are a few layers with range 2, so they are in position 0 every other picosecond. So we could increment the delay by 2 instead of 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 14\n",
    "## Part 1\n",
    "> The disk in question consists of a 128x128 grid; each square of the grid is either free or used. On this disk, the state of the grid is tracked by the bits in a sequence of knot hashes.\n",
    "\n",
    "> A total of 128 knot hashes are calculated, each corresponding to a single row in the grid; each hash contains 128 bits which correspond to individual grid squares. Each bit of a hash indicates whether that square is free (0) or used (1).\n",
    "\n",
    "> The hash inputs are a key string (your puzzle input), a dash, and a number from 0 to 127 corresponding to the row. For example, if your key string were flqrgnkx, then the first row would be given by the bits of the knot hash of flqrgnkx-0, the second row from the bits of the knot hash of flqrgnkx-1, and so on until the last row, flqrgnkx-127.\n",
    "\n",
    "> Given your actual key string, how many squares are used?\n",
    "\n",
    "This is straightforward. Use a lookup table to match each hexadecimal digit to the number of bits, then sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_set(hexchar):\n",
    "    return {'0':0, '1':1, '2':1, '3': 2,\n",
    "            '4':1, '5':2, '6':2, '7': 3,\n",
    "            '8':1, '9':2, 'a':2, 'b': 3,\n",
    "            'c':2, 'd':3, 'e':3, 'f': 4}[hexchar]\n",
    "\n",
    "def defragment_count(input):\n",
    "    grid = [full_knot_hash(K) for K in [\"%s-%d\" % (input, i) for i in range(128)]]\n",
    "    return sum([bits_set(h) for line in grid for h in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for a nested list comprehension (without creating a list of lists) was not obvious to me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8230"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'flqrgnkx'\n",
    "assert(defragment_count(test)) == 8108\n",
    "\n",
    "input = 'hfdlxzhv'\n",
    "defragment_count(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A region is a group of used squares that are all adjacent, not including diagonals. Every used square is in exactly one region: lone used squares form their own isolated regions, while several adjacent squares all count as a single region.\n",
    "> How many regions are present given your key string?\n",
    "\n",
    "My initial thinking is that we can maintain a map from each bit/square's co-ordinate to their region. As we visit a square, we check to see if it has any neighbours. If so, we coalesce all of the neighbors into the same region. If not, we assign it to a new region. At the end, we can tell how many regions were needed to be assigned. A data structure for this would just be a simple map, from coordinate to region. \n",
    "\n",
    "First, I needed to modify some code from Part 1, to convert the knot hash output into a list of bit values. The list comprehension syntax took a while to get right: I certainly didn't write those nested expressions in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bit_tuple(hexchar):\n",
    "    return {'0':(0,0,0,0), '1':(0,0,0,1), '2':(0,0,1,0), '3': (0,0,1,1),\n",
    "        '4':(0,1,0,0), '5':(0,1,0,1), '6':(0,1,1,0), '7': (0,1,1,1),\n",
    "        '8':(1,0,0,0), '9':(1,0,0,1), 'a':(1,0,1,0), 'b': (1,0,1,1),\n",
    "        'c':(1,1,0,0), 'd':(1,1,0,1), 'e':(1,1,1,0), 'f': (1,1,1,1)}[hexchar]\n",
    "\n",
    "def make_full_grid(input):\n",
    "    \"Calculate the knot hashes from the input, and return a list of lists, with each element set to 0 (if square is free) or 1 (if square is used)\"\n",
    "    grid = [full_knot_hash(K) for K in [\"%s-%d\" % (input, i) for i in range(128)]]\n",
    "    return [[item for sublist in [list(hex_to_bit_tuple(c)) for c in line] for item in sublist] for line in grid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after trying to implement my initial idea, I realized I had a problem: when I come across a node with several neighbors that belong to different regions, I need to coalesce them all into the same region. This means either a linear scan on the values of the map, or maintaining an inverse map.\n",
    "\n",
    "Then, in the back of my mind, I recalled the [union-find algorithm](https://en.wikipedia.org/wiki/Disjoint-set_data_structure). My revised idea was to use this structure to combine adjacent regions (**union**) into the same set. I found an [implementation of union-find](https://www.nayuki.io/page/disjoint-set-data-structure) in Python from Project Nayuki. It represents disjoint sets using a number, so I first build a map (`region_map`) from the grid square to a set number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.disjointset import DisjointSet\n",
    "\n",
    "def initialize_defrag_part2_structs(full_grid):\n",
    "    \"Assign each unique square to a unique set number, returning the map and number of sets used.\"\n",
    "    region_map = {}\n",
    "    set_num = 0\n",
    "    for y in range(128):\n",
    "        for x in range(128):\n",
    "            if full_grid[y][x] == 1:\n",
    "                region_map[(x,y)] = set_num\n",
    "                set_num += 1\n",
    "    return region_map, set_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also need a function to return the neighbours of a square. Since we're going to traverse the grid from left to right, top to bottom, we only need to look at squares we've encountered previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(coord, max_coord):\n",
    "    \"Given a left-to-right, top-to-bottom traversal of a grid, return a list of the visited neighbors of the given coordinate. A neighbor is an adjacent square, not including diagonals.\"\n",
    "    neighbors = []\n",
    "    (x, y) = coord\n",
    "    if x > 0:\n",
    "        neighbors.append((x-1, y))\n",
    "    if y > 0:\n",
    "        neighbors.append((x, y-1))\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discover the connected regions, we go through the neighbors of all used squares, and merge them into the same set. I ran into an oddity while trying to iterate a Python `defaultdict`, getting the error `dictionary changed size during iteration`. I realized I didn't need the default behavior, since the only neighbors we care about, are the ones that are used. So I switched to a regular dictionary for `region_map` and the problem went away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_disjoint_sets(region_map, disjoint_set):\n",
    "    for coord, my_region in region_map.items():\n",
    "        neighbors = get_neighbors(coord, 128)\n",
    "        neighbor_regions = set([region_map[k] if k in region_map else None for k in neighbors]) - {None}\n",
    "        for n in neighbor_regions:\n",
    "            disjoint_set.merge_sets(my_region, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def day14_part2(input):\n",
    "    grid = make_full_grid(input)\n",
    "    region_map, num_sets = initialize_defrag_part2_structs(grid)\n",
    "    disjoint_set = DisjointSet(num_sets)\n",
    "    build_disjoint_sets(region_map, disjoint_set)\n",
    "    return disjoint_set.get_num_sets()\n",
    "\n",
    "assert(day14_part2('flqrgnkx')) == 1242\n",
    "\n",
    "my_input = 'hfdlxzhv'\n",
    "day14_part2(my_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 15\n",
    "## Part 1\n",
    "> The generators, called generator A and generator B, are trying to agree on a sequence of numbers. \n",
    "> As they do this, a judge waits for each of them to generate its next value, compares the lowest 16 bits of both values, and keeps track of the number of times those parts of the values match.\n",
    "> The generators both work on the same principle. To create its next value, a generator will take the previous value it produced, multiply it by a factor (generator A uses 16807; generator B uses 48271), and then keep the remainder of dividing that resulting product by 2147483647. That final remainder is the value it produces next.\n",
    "> Suppose that for starting values, generator A uses 65, while generator B uses 8921.\n",
    "\n",
    "The naive implementation of this is simple to implement, but it takes about a minute on my machine to run and get the right answer. The value 2147483647 is all ones in binary, and I thought this could be exploited somehow, but I couldn't figure it out. I looked at modular multiplication algorithms, residue number systems, and then landed on Mersenne primes.\n",
    "\n",
    "I then noticed that the modulus is `2^31 - 1` which is a Mersenne prime. But… not sure how that helps me.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "def generator_part1(start, factor):\n",
    "    acc = start\n",
    "    yield start\n",
    "    while True:\n",
    "        acc = (acc * factor) % 2147483647\n",
    "        yield acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_part1_test():\n",
    "    A = generator_part1(65, 16807)\n",
    "    B = generator_part1(8921, 48271)\n",
    "    n = sum([int(next(A) & 65535 == next(B) & 65535) for i in range(40_000_000)])\n",
    "    print(n)\n",
    "    \n",
    "#timeit.timeit(judge_part1_test, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.98723808300201"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def judge_part1_input():\n",
    "    A = generator_part1(116, 16807)\n",
    "    B = generator_part1(299, 48271)\n",
    "    n = sum([int(next(A) & 65535 == next(B) & 65535) for i in range(40_000_000)])\n",
    "    print(n)\n",
    "    \n",
    "timeit.timeit(judge_part1_input, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> now they only hand a value to the judge when it meets their criteria:\n",
    "> Generator A looks for values that are multiples of 4.\n",
    "> Generator B looks for values that are multiples of 8.\n",
    "> Each generator functions completely independently\n",
    "> This change makes the generators much slower, and the judge is getting impatient; it is now only willing to consider 5 million pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_part2(start, factor, multiple):\n",
    "    acc = start\n",
    "    yield start\n",
    "    while True:\n",
    "        acc = (acc * factor) % 2147483647\n",
    "        if (acc % multiple == 0):\n",
    "            yield acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_part2_test():\n",
    "    A = generator_part2(65, 16807, 4)\n",
    "    B = generator_part2(8921, 48271, 8)\n",
    "    n = sum([int(next(A) & 65535 == next(B) & 65535) for i in range(5_000_000)])\n",
    "    print(n)\n",
    "    \n",
    "#timeit.timeit(judge_part2_test, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.71304503900319"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def judge_part2_input():\n",
    "    A = generator_part2(116, 16807, 4)\n",
    "    B = generator_part2(299, 48271, 8)\n",
    "    n = sum([int(next(A) & 65535 == next(B) & 65535) for i in range(5_000_000)])\n",
    "    print(n)\n",
    "    \n",
    "timeit.timeit(judge_part2_input, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 16\n",
    "## Part 1\n",
    "> There are sixteen programs in total, named a through p. They start by standing in a line: a stands in position 0, b stands in position 1, and so on until p, which stands in position 15.\n",
    "\n",
    "> The programs' dance consists of a sequence of dance moves:\n",
    "\n",
    "> - Spin, written sX, makes X programs move from the end to the front, but maintain their order otherwise. (For example, s3 on abcde produces cdeab).\n",
    "> - Exchange, written xA/B, makes the programs at positions A and B swap places.\n",
    "> - Partner, written pA/B, makes the programs named A and B swap places.\n",
    "\n",
    "This seems straightforward, with the exception of Partner. Instead of a linear scan, perhaps we can maintain a map from program to index, updated after every move. This way, Partner can be implemented as Exchange. Python's list manipulation should make Spin a breeze. To avoid extra memory allocation, we want to use a list as a data structure, but not create a new list, especially on the spin operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class PermutationPromenade:\n",
    "    def __init__(self,init_list):\n",
    "        \"Initializes this class with the given programs in their initial order.\"\n",
    "        self.len = len(init_list)\n",
    "        # Maintain two lists, to avoid new list allocation when performing the spin op.\n",
    "        # We maintain a current pointer to know which list is the current one.\n",
    "        self.L1 = list(init_list)\n",
    "        self.L2 = [None] * self.len\n",
    "        # Maps from program name to position, to transform the partner op into the exchange op\n",
    "        self.prog_map = {k:v for k, v in zip(init_list, range(self.len))}\n",
    "        self.current = self.L1\n",
    "        self.other = self.L2\n",
    "        \n",
    "    def spin(self, x):\n",
    "        \"Makes X programs move from the end to the front, but maintain their order otherwise.\"\n",
    "        for i in range(self.len-x, self.len):\n",
    "            self.other[i-self.len+x] = self.current[i]\n",
    "        for i in range(0, self.len-x):\n",
    "            self.other[i+x] = self.current[i]\n",
    "        #print(self.other)\n",
    "        self.current, self.other = self.other, self.current\n",
    "        self.prog_map.update({k:v for k, v in zip(self.current, range(self.len))})\n",
    "        #print(self.current)\n",
    "    \n",
    "    def exchange(self, posA, posB):\n",
    "        \"Makes the programs at positions A and B swap places\"\n",
    "        self.prog_map[self.current[posA]] = posB\n",
    "        self.prog_map[self.current[posB]] = posA\n",
    "        self.current[posA], self.current[posB] = self.current[posB], self.current[posA]\n",
    "        #print(self.current)\n",
    "\n",
    "    def partner(self, nameA, nameB):\n",
    "        \"Makes the programs named A and B swap places\"\n",
    "        posA = self.prog_map[nameA]\n",
    "        posB = self.prog_map[nameB]\n",
    "        return self.exchange(posA, posB)\n",
    "\n",
    "    def parse_instrs(self, instrs):\n",
    "        \"Given a list of instructions, parse them and build an internal list that can be exec() or eval() later.\"\n",
    "        self.parsed_instrs = []\n",
    "        for instr in instrs:\n",
    "            #print(instr)\n",
    "            if instr[0] == 's':\n",
    "                m = re.match(r\"s(\\d+)\", instr)\n",
    "                x = int(m[1])\n",
    "                #self.spin(x)\n",
    "                self.parsed_instrs.append('self.spin(%d)' % x)\n",
    "            elif instr[0] == 'x':\n",
    "                m = re.match(r\"x(\\d+)/(\\d+)\", instr)\n",
    "                a = int(m[1])\n",
    "                b = int(m[2])\n",
    "                #self.exchange(a, b)\n",
    "                self.parsed_instrs.append('self.exchange(%d,%d)' % (a,b))\n",
    "            elif instr[0] == 'p':\n",
    "                m = re.match(r\"p(.)/(.)\", instr)\n",
    "                a = m[1]\n",
    "                b = m[2]\n",
    "                #self.partner(a, b)\n",
    "                self.parsed_instrs.append('self.partner(\\'%s\\',\\'%s\\')' % (a,b))\n",
    "\n",
    "    def execute_parsed(self):\n",
    "        for instr in self.parsed_instrs:\n",
    "            exec(instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baedc'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = PermutationPromenade(list('abcde'))\n",
    "test.parse_instrs(['s1','x3/4', 'pe/b'])\n",
    "test.execute_parsed()\n",
    "''.join(test.current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ceijbfoamgkdnlph'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = PermutationPromenade(list('abcdefghijklmnop'))\n",
    "real.parse_instrs(Input(16).read().split(','))\n",
    "real.execute_parsed()\n",
    "''.join(real.current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> Keeping the positions they ended up in from their previous dance, the programs perform it again and again: including the first dance, a total of one billion (1000000000) times.\n",
    "\n",
    "> In what order are the programs standing after their billion dances?\n",
    "\n",
    "After iterating for a while, I realized that executing the dance a billion times would take a long time. Unfortunately, I made the incorrect assumption that optimizing my code would help. I tried:\n",
    "\n",
    "- Implementing the `spin` operation without additional memory allocation, by maintaining two lists, and copying from one to the other\n",
    "- Parsing the set of dance moves once, storing them as a list of Python code strings, then replaying them on the list via `exec()`\n",
    "\n",
    "I knew there had to be a trick to this puzzle, and it too me too long to realize that perhaps the set of dance moves resulted in a sequence of positions that repeated. By adding a cache, I was able to figure out the cycle length. Then, it's just a simple modular operation to determine which position we would be in after a billion iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cycle(init_list):\n",
    "    \"Given the initial list, perform the permutation dance repeatedly until a cycle is found. Return a list of positions indexed by the number of dances to arrive at that position; the size of the list is the size of the cycle.\"\n",
    "    P = PermutationPromenade(init_list)\n",
    "    instrs = Input(16).read().split(',')\n",
    "    P.parse_instrs(instrs)\n",
    "    cache = [''.join(init_list)]\n",
    "    while True:\n",
    "        P.execute_parsed()\n",
    "        if ''.join(P.current) in cache:\n",
    "            return cache\n",
    "        cache.append(''.join(P.current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pnhajoekigcbflmd'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycles = find_cycle(list('abcdefghijklmnop'))\n",
    "cycles[1_000_000_000 % 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 17\n",
    "## Part 1\n",
    "> It starts with a circular buffer containing only the value 0, which it marks as the current position. It then steps forward through the circular buffer some number of steps (your puzzle input) before inserting the first new value, 1, after the value it stopped on. The inserted value becomes the current position. Then, it steps forward from there the same number of steps, and wherever it stops, inserts after it the second new value, 2, and uses that as the new current position again.\n",
    "\n",
    "> It repeats this process of stepping forward, inserting a new value, and using the location of the inserted value as the new current position a total of 2017 times, inserting 2017 as its final operation, and ending with a total of 2018 values (including 0) in the circular buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spinlock(steps, times):\n",
    "    buf = [0]\n",
    "    pos = 0\n",
    "    for i in range(1,times+1):\n",
    "        pos = (pos + steps % len(buf)) % len(buf)\n",
    "        buf.insert(pos+1, i)\n",
    "        pos += 1\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spinlock(3, 2017)\n",
    "assert(test[(test.index(2017)+1) % len(test)]) == 638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1561"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = spinlock(382, 2017)\n",
    "real[(real.index(2017)+1) % len(real)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "> The spinlock has just finished inserting its fifty millionth value (50000000).\n",
    "> What is the value after 0 the moment 50000000 is inserted?\n",
    "\n",
    "There are two key insights here: the first is that the 0 element is fixed. Since new elements are always inserted after a given position, 0 will never move. The second is that we don't need to keep extending a list to hold fifty million items, we just need to calculate the new current positions, and remember what value we (pretended to) insert there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angry_spinlock(steps, times):\n",
    "    buf_len = 1 # Starts with [0]\n",
    "    pos = 0\n",
    "    insert_after_0 = None\n",
    "    for i in range(1,times+1):\n",
    "        pos = (pos + steps % buf_len) % buf_len\n",
    "        if pos == 0:\n",
    "            insert_after_0 = i\n",
    "        buf_len += 1\n",
    "        pos += 1\n",
    "    return insert_after_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33454823"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angry_spinlock(382, 50_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 18\n",
    "## Part 1\n",
    "> the assembly is meant to operate on a set of registers that are each named with a single letter and that can each hold a single integer. You suppose each register should start with a value of 0.\n",
    "> - `snd X` plays a sound with a frequency equal to the value of X.\n",
    "> - `set X Y` sets register X to the value of Y.\n",
    "> - `add X Y` increases register X by the value of Y.\n",
    "> - `mul X Y` sets register X to the result of multiplying the value contained in register X by the value of Y.\n",
    "> - `mod X Y` sets register X to the remainder of dividing the value contained in register X by the value of Y (that is, it sets X to the result of X modulo Y).\n",
    "> - `rcv X` recovers the frequency of the last sound played, but only when the value of X is not zero. (If it is zero, the command does nothing.)\n",
    "> - `jgz X Y` jumps with an offset of the value of Y, but only if the value of X is greater than zero. (An offset of 2 skips the next instruction, an offset of -1 jumps to the previous instruction, and so on.)\n",
    "\n",
    "> Many of the instructions can take either a register (a single letter) or a number. The value of a register is the integer it contains; the value of a number is that number.\n",
    "> After each jump instruction, the program continues with the instruction to which the jump jumped. After any other instruction, the program continues with the next instruction. Continuing (or jumping) off either end of the program terminates it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "    \n",
    "class Duet:\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        self.last_sound = None\n",
    "        self.regs = defaultdict(lambda: 0)\n",
    "        self.char_re = re.compile(\"[a-z]\")\n",
    "    \n",
    "    def get_assembly_value(self, arg):\n",
    "        \"Given an assembly value, return the register value, if the argument is a register; otherwise, the value itself.\"\n",
    "        if self.char_re.fullmatch(arg):\n",
    "            return self.regs[arg]\n",
    "        else:\n",
    "            return int(arg)\n",
    "\n",
    "    def run(self):\n",
    "        next_line = 0\n",
    "        while next_line in range(0, len(self.lines)):\n",
    "            next_line = self.execute_line(next_line)\n",
    "        print(\"Done execution\")\n",
    "            \n",
    "    def execute_line(self, line_index):\n",
    "        offset = 1\n",
    "        line = self.lines[line_index]\n",
    "        if line[0:3] == 'snd':\n",
    "            arg = re.match(r\"snd (.+)\", line).groups()[0]\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.last_sound = val\n",
    "        elif line[0:3] == 'set':\n",
    "            reg, arg = re.match(r\"set (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] = val\n",
    "        elif line[0:3] == 'add':\n",
    "            reg, arg = re.match(r\"add (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] += val\n",
    "        elif line[0:3] == 'mul':\n",
    "            reg, arg = re.match(r\"mul (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] *= val\n",
    "        elif line[0:3] == 'mod':\n",
    "            reg, arg = re.match(r\"mod (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] %= val\n",
    "        elif line[0:3] == 'rcv':\n",
    "            arg = re.match(r\"rcv (.+)\", line).groups()[0]\n",
    "            val = self.get_assembly_value(arg)\n",
    "            if val != 0:\n",
    "                print(\"Recovered value %d\" % (self.last_sound))\n",
    "                offset = 2*len(self.lines) # Really big offset to stop program\n",
    "        elif line[0:3] == 'jgz':\n",
    "            X, arg = re.match(r\"jgz (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            check = self.get_assembly_value(X)\n",
    "            if check > 0:\n",
    "                offset = val\n",
    "        \n",
    "        return line_index + offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"set a 1\n",
    "add a 2\n",
    "mul a a\n",
    "mod a 5\n",
    "snd a\n",
    "set a 0\n",
    "rcv a\n",
    "jgz a -1\n",
    "set a 1\n",
    "jgz a -2\"\"\"\n",
    "\n",
    "test_duet = Duet(test.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered value 4\n",
      "Done execution\n"
     ]
    }
   ],
   "source": [
    "test_duet.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered value 4601\n",
      "Done execution\n"
     ]
    }
   ],
   "source": [
    "real = Input(18).read().splitlines()\n",
    "real_duet = Duet(real)\n",
    "real_duet.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> This assembly code isn't about sound at all - it's meant to be run twice at the same time.\n",
    "\n",
    "> Each running copy of the program has its own set of registers and follows the code independently - in fact, the programs don't even necessarily run at the same speed. To coordinate, they use the send (snd) and receive (rcv) instructions:\n",
    "\n",
    "> `snd X` sends the value of X to the other program. These values wait in a queue until that program is ready to receive them. Each program has its own message queue, so a program can never receive a message it sent.\n",
    "\n",
    "> `rcv X` receives the next value and stores it in register X. If no values are in the queue, the program waits for a value to be sent to it. Programs do not continue to the next instruction until they have received a value. Values are received in the order they are sent.\n",
    "\n",
    "> Each program also has its own program ID (one 0 and the other 1); the register p should begin with this value.\n",
    "\n",
    "> \\[if\\] no data is waiting for either of them, and they reach a deadlock. When this happens, both programs terminate.\n",
    "\n",
    "> Once both of your programs have terminated (regardless of what caused them to do so), how many times did program 1 send a value?\n",
    "\n",
    "Instead of actually implementing a blocking producer-consumer implementation, my plan is to execute steps of both programs one at a time using a \"controller\", and manually pass the values back and forth. The controller program will be responsible for receiving values and \"restarting\" a program that is waiting.\n",
    "\n",
    "I debugged an infinite loop for a long time on this one, eventually turning to the [subreddit](https://www.reddit.com/r/adventofcode/) for help. I made a mistake that tripped many people up: not noticing that the `jgz` instruction allows register names _and_ values in _both_ arguments.\n",
    "\n",
    "Two gotchas about Python that I learned:\n",
    "\n",
    "- Python's syntax for a 1-element tuple is `(1,)`, i.e. don't forget the trailing comma\n",
    "- To implement the queue of send/receive values, I used a list. `list.pop()` removes the **last** element, i.e. the item most recently added by `list.append()`. What I needed was `list.pop(0)`, which removes from the front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Duet2:\n",
    "    def __init__(self, lines, program_id):\n",
    "        self.lines = lines\n",
    "        self.regs = defaultdict(lambda: 0)\n",
    "        self.char_re = re.compile(\"[a-z]\")\n",
    "        self.regs['p'] = program_id\n",
    "        self.id = program_id\n",
    "    \n",
    "    def get_assembly_value(self, arg):\n",
    "        \"Given an assembly value, return the register value, if the argument is a register; otherwise, the value itself.\"\n",
    "        if self.char_re.fullmatch(arg):\n",
    "            return self.regs[arg]\n",
    "        else:\n",
    "            return int(arg)\n",
    "\n",
    "    def execute_line(self, line_index, received):\n",
    "        \"Parse the instruction specified by the line index, returning a tuple of \\\n",
    "        ('next', <next_line_num>), ('end'), ('wait') or ('send', <value>, <next_line_num>)\" \n",
    "        status = 'next'\n",
    "        offset = 1\n",
    "        send_val = None\n",
    "        line = self.lines[line_index]\n",
    "\n",
    "        #print('{} executing {}, '.format(self.id, line), end='')\n",
    "        \n",
    "        if line[0:3] == 'snd':\n",
    "            arg = re.match(r\"snd (.+)\", line).groups()[0]\n",
    "            send_val = self.get_assembly_value(arg)\n",
    "            status = 'send'\n",
    "        elif line[0:3] == 'set':\n",
    "            reg, arg = re.match(r\"set (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] = val\n",
    "        elif line[0:3] == 'add':\n",
    "            reg, arg = re.match(r\"add (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] += val\n",
    "        elif line[0:3] == 'mul':\n",
    "            reg, arg = re.match(r\"mul (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] *= val\n",
    "        elif line[0:3] == 'mod':\n",
    "            reg, arg = re.match(r\"mod (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] %= val\n",
    "        elif line[0:3] == 'rcv':\n",
    "            if len(received) != 0:\n",
    "                reg = re.match(r\"rcv (.+)\", line).groups()[0]\n",
    "                self.regs[reg] = received.pop(0)\n",
    "            else:\n",
    "                status = 'wait'\n",
    "                offset = 0\n",
    "        elif line[0:3] == 'jgz':\n",
    "            X, arg = re.match(r\"jgz (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            check = self.get_assembly_value(X)\n",
    "            if check > 0:\n",
    "                offset = val\n",
    "        \n",
    "        \n",
    "        if (line_index + offset) >= len(self.lines):\n",
    "            status = 'end'\n",
    "            \n",
    "        if status == 'next':\n",
    "            return (status, line_index + offset)\n",
    "        elif status == 'wait' or status == 'end':\n",
    "            return (status,)\n",
    "        elif status == 'send':\n",
    "            return (status, send_val, line_index + offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real = Input(18).read().splitlines()\n",
    "\n",
    "P0 = Duet2(real, 0)\n",
    "P1 = Duet2(real, 1)\n",
    "\n",
    "# Values sent from each program\n",
    "P0sendQ = []\n",
    "P1sendQ = []\n",
    "# Result of each instruction execution\n",
    "status0 = ('next', 0)\n",
    "status1 = ('next', 0)\n",
    "# Next instruction\n",
    "P0next = status0[1] \n",
    "P1next = status1[1]\n",
    "# Times P1 sent\n",
    "P1send = 0\n",
    "while True:\n",
    "    if status0[0] != 'end':\n",
    "        status0 = P0.execute_line(P0next, P1sendQ)\n",
    "    if status1[0] != 'end':\n",
    "        status1 = P1.execute_line(P1next, P0sendQ)\n",
    "    \n",
    "    #print(\"\")\n",
    "    #print(\"Status: 0: {}, 1: {}\".format(status0, status1))\n",
    "    if status0[0] == 'next':\n",
    "        P0next = status0[1]\n",
    "    elif status0[0] == 'end':\n",
    "        pass\n",
    "    elif status0[0] == 'wait':\n",
    "        pass\n",
    "    elif status0[0] == 'send':\n",
    "        P0sendQ.append(status0[1])\n",
    "        P0next = status0[2]\n",
    "        \n",
    "    if status1[0] == 'next':\n",
    "        P1next = status1[1]\n",
    "    elif status1[0] == 'end':\n",
    "        pass\n",
    "    elif status1[0] == 'wait':\n",
    "        pass\n",
    "    elif status1[0] == 'send':\n",
    "        P1send += 1\n",
    "        P1sendQ.append(status1[1])\n",
    "        P1next = status1[2]\n",
    "        \n",
    "    if (status0[0] == 'wait' and status1[0] == 'wait') or \\\n",
    "       (status0[0] == 'wait' and status1[0] == 'end') or \\\n",
    "       (status0[0] == 'end' and status1[0] == 'wait') or \\\n",
    "       (status0[0] == 'end' and status1[0] == 'end'):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6858"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1send"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 19\n",
    "## Part 1\n",
    "> Lines (drawn with |, -, and +) show the path it needs to take, starting by going down onto the only line connected to the top of the diagram. It needs to follow this path until it reaches the end (located somewhere within the diagram) and stop there.\n",
    "\n",
    "> Sometimes, the lines cross over each other; in these cases, it needs to continue going the same direction, and only turn left or right when there's no other option. In addition, someone has left letters on the line\n",
    "> What letters will it see (in the order it would see them) if it follows the path?\n",
    "\n",
    "My approach is going to be reading in the entire diagram into a list of lists. Keep track of the current direction, and wander through the array. If the same symbol is seen, continue in the same direction. If a letter is seen, add it to a list. If a `+` is seen, look ahead in the same direction to see if we can keep going, or if we're at the edge; if not, look left then right to see if path continues there and change direction. If the opposite symbol is seen, we're at a crossing, and should continue in same direction.\n",
    "\n",
    "## Part 2\n",
    "> The packet is curious how many steps it needs to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def find_start(grid):\n",
    "    \"Given a list of lists representing the diagram, find the coordinate of the first | when scanning left to right, top to bottom.\"\n",
    "    height = len(grid)\n",
    "    width = len(grid[0])\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            if grid[j][i] == '|':\n",
    "                return (i,j)\n",
    "\n",
    "def within_grid(coord, grid_width, grid_height):\n",
    "    \"Returns whether the given coord is within the grid boundaries.\"\n",
    "    (i,j) = coord\n",
    "    return i in range(0, grid_width) and j in range(0, grid_height)\n",
    "\n",
    "def traverse_map(grid):\n",
    "    \"Given a list of lists representing the diagram, find the start, and follow it, returning the letters seen in order as a single string.\"\n",
    "    gw, gh = len(grid[0]), len(grid)\n",
    "    (i, j) = find_start(grid)\n",
    "    dir = 's'\n",
    "    letters = []\n",
    "    steps = 0\n",
    "    while True:\n",
    "        #print(\"{} {}\".format(grid[j][i], (i,j)), end='')\n",
    "        next_dir = dir\n",
    "        sym = grid[j][i]\n",
    "        if sym == '|':\n",
    "            steps += 1\n",
    "            if dir == 's' or dir == 'n':\n",
    "                pass\n",
    "            elif dir == 'e' or dir == 'w':\n",
    "                #print(\"Crossing at {}, continuing\".format((i,j)), end='')\n",
    "                pass\n",
    "        elif sym == '-':\n",
    "            steps += 1\n",
    "            if dir == 's' or dir == 'n':\n",
    "                #print(\"Crossing at {}, continuing\".format((i,j)), end='')\n",
    "                pass\n",
    "            elif dir == 'e' or dir == 'w':\n",
    "                pass\n",
    "        elif sym == '+':\n",
    "            steps += 1\n",
    "            if dir in ['n', 's']:\n",
    "                if within_grid((i+1,j), gw, gh) and grid[j][i+1] == '-':\n",
    "                    next_dir = 'e'\n",
    "                elif within_grid((i-1, j), gw, gh) and grid[j][i-1] == '-':\n",
    "                    next_dir = 'w'\n",
    "            elif dir in ['e', 'w']:\n",
    "                if within_grid((i,j+1), gw, gh) and grid[j+1][i] == '|':\n",
    "                    next_dir = 's'\n",
    "                elif within_grid((i, j-1), gw, gh) and grid[j-1][i] == '|':\n",
    "                    next_dir = 'n'\n",
    "                   \n",
    "        elif sym in string.ascii_uppercase:\n",
    "            steps += 1\n",
    "            letters.append(sym)\n",
    "            #print(\"Saw %s\" % sym)\n",
    "            # dir stays the same\n",
    "        else:\n",
    "            return ''.join(letters), steps\n",
    "\n",
    "        if dir != next_dir:\n",
    "            #print(\"Changing dir from {} to {}\".format(dir, next_dir), end='')\n",
    "            dir = next_dir\n",
    "            \n",
    "        if dir == 's':\n",
    "            j += 1\n",
    "        elif dir == 'n':\n",
    "            j -= 1\n",
    "        elif dir == 'e':\n",
    "            i += 1\n",
    "        elif dir == 'w':\n",
    "            i -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GINOWKYXH', 16636)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = [list(line) for line in Input(19).read().splitlines()]\n",
    "traverse_map(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 20\n",
    "## Part 1\n",
    "> a buffer (your puzzle input) listing each particle in order (starting with particle 0, then particle 1, particle 2, and so on). For each particle, it provides the X, Y, and Z coordinates for the particle's position (p), velocity (v), and acceleration (a), each in the format <X,Y,Z>.\n",
    "\n",
    "> Each tick, all particles are updated simultaneously. A particle's properties are updated in the following order:\n",
    "\n",
    "> - Increase the X velocity by the X acceleration.\n",
    "> - Increase the Y velocity by the Y acceleration.\n",
    "> - Increase the Z velocity by the Z acceleration.\n",
    "> - Increase the X position by the X velocity.\n",
    "> - Increase the Y position by the Y velocity.\n",
    "> - Increase the Z position by the Z velocity.\n",
    "\n",
    "> which particle will stay closest to position <0,0,0> in the long term. Measure this using the Manhattan distance, which in this situation is simply the sum of the absolute values of a particle's X, Y, and Z position.\n",
    "\n",
    "Running the simulation, then outputting a sorted list of the five nearest particles, then seeing if their rankings start to stabilize, is my first guess at how to model this.\n",
    "\n",
    "I learned to be carefully about naming variables after reserved words, and built-in functions, e.g. `list` or `map`. If you do, you'll get hard-to-debug errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "class Particle:\n",
    "    def __init__(self, particle_id, pos, vel, acc):\n",
    "        self.id = particle_id\n",
    "        self.pos = pos\n",
    "        self.vel = vel\n",
    "        self.acc = acc\n",
    "        \n",
    "    def update(self):\n",
    "        self.vel = list(map(add, self.vel, self.acc))\n",
    "        self.pos = list(map(add, self.pos, self.vel))\n",
    "        \n",
    "    def distance_from(self, other):\n",
    "        return sum([abs(other[i] - self.pos[i]) for i in [0,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swarm(lines, iters):\n",
    "    particles = {}\n",
    "    particle_id = 0\n",
    "    for line in lines:\n",
    "        g = re.match(r\"p=<(-?\\d+),(-?\\d+),(-?\\d+)>, v=<(-?\\d+),(-?\\d+),(-?\\d+)>, a=<(-?\\d+),(-?\\d+),(-?\\d+)>\", line).groups()\n",
    "        pos = [int(g[0]), int(g[1]), int(g[2])]\n",
    "        vel = [int(g[3]), int(g[4]), int(g[5])]\n",
    "        acc = [int(g[6]), int(g[7]), int(g[8])]\n",
    "        particles[particle_id] = Particle(particle_id, pos, vel, acc)\n",
    "        particle_id += 1\n",
    "    for i in range(iters):\n",
    "        for P in particles.values():\n",
    "            P.update()\n",
    "\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = Input(20).readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[364, 485, 205, 46, 396]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = swarm(real, 700)\n",
    "out = sorted(P.values(), key=lambda P: P.distance_from([0,0,0]))\n",
    "[x.id for x in out[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[364, 485, 205, 46, 396]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = swarm(real, 1000)\n",
    "out = sorted(P.values(), key=lambda P: P.distance_from([0,0,0]))\n",
    "[x.id for x in out[0:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> Particles collide if their positions ever exactly match. Because particles are updated simultaneously, more than two particles can collide at the same time and place. Once particles collide, they are removed and cannot collide with anything else after that tick.\n",
    "> How many particles are left after all collisions are resolved?\n",
    "\n",
    "Keep a map of position to particles. Update as usual, adding all particles to map. On each pass through, if we know that a position has more than one particle, remove them from the map. Run a few times with increasing iterations to see when we reach a steady state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def handle_collisions(lines, iters):\n",
    "    space = defaultdict(lambda: []) # Map from location tuple to particle IDs\n",
    "    particles = swarm(lines, 0)\n",
    "\n",
    "    for i in range(iters):\n",
    "        collision_locations = []\n",
    "        for P in particles.values():\n",
    "            P.update()\n",
    "            new_pos = tuple(P.pos)\n",
    "            space[new_pos].append(P.id)\n",
    "            if len(space[new_pos]) > 1:\n",
    "                collision_locations.append(new_pos)\n",
    "        if len(collision_locations) > 0:\n",
    "            for loc in collision_locations:\n",
    "                tbd = space[loc]\n",
    "                for particle_id in tbd:\n",
    "                    try:\n",
    "                        del particles[particle_id]\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    \n",
    "    return len(particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_collisions(real, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_collisions(real, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21\n",
    "## Part 1\n",
    "> The image consists of a two-dimensional square grid of pixels that are either on (#) or off (.). The program always begins with this pattern:\n",
    "```\n",
    ".#.\n",
    "..#\n",
    "###\n",
    "```\n",
    "> Because the pattern is both 3 pixels wide and 3 pixels tall, it is said to have a **size** of 3.\n",
    "\n",
    "> Then, the program repeats the following process:\n",
    "\n",
    "> - If the size is evenly divisible by 2, break the pixels up into 2x2 squares, and convert each 2x2 square into a 3x3 square by following the corresponding enhancement rule.\n",
    "> - Otherwise, the size is evenly divisible by 3; break the pixels up into 3x3 squares, and convert each 3x3 square into a 4x4 square by following the corresponding enhancement rule.\n",
    "\n",
    "> Because each square of pixels is replaced by a larger one, the image gains pixels and so its **size** increases.\n",
    "\n",
    "> The artist's book of enhancement rules is nearby (your puzzle input); however, it seems to be missing rules. The artist explains that sometimes, one must **rotate** or **flip** the input pattern to find a match. (Never rotate or flip the output pattern, though.) Each pattern is written concisely: rows are listed as single units, ordered top-down, and separated by slashes.\n",
    "\n",
    "Some thoughts:\n",
    "\n",
    "- `numpy` arrays have a lot of methods for manipulating matrices and we'll need to flip and rotate, and combine and split\n",
    "- We'll need methods to turn the concise enhancement rules into matrices and v.v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_from_pattern(patt):\n",
    "    rows = patt.split('/')\n",
    "    return np.matrix([list(row) for row in rows])\n",
    "\n",
    "def pattern_from_matrix(A):\n",
    "    return '/'.join([''.join(row) for row in A.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rotates_and_flips(A):\n",
    "    \"Return a set of A itself, its flips (horiz, vert, horiz+vert) and three rotations (90, 180, 270) and their combination\"\n",
    "    return set([pattern_from_matrix(M) for M in [A, np.fliplr(A), np.flipud(A), np.rot90(A), np.flipud(np.rot90(A)), np.fliplr(np.rot90(A)), np.rot90(A, 2), np.rot90(A, 3)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_fractal_rules(lines):\n",
    "    \"Add each rule to a dictionary, and pre-compute the rotates/flips for each input.\"\n",
    "    rules = {}\n",
    "    for line in lines:\n",
    "        inp, out = re.match(r\"([./#]+) => ([./#]+)\", line).groups()\n",
    "        xforms = make_rotates_and_flips(matrix_from_pattern(inp))\n",
    "        for x in xforms:\n",
    "            rules[x] = out\n",
    "    return rules\n",
    "\n",
    "def enhancement_matrix(rules, patt):\n",
    "    \"Given a pattern representing a matrix, returns the output matrix based on the enhancement rules.\"\n",
    "    #xformpatts = make_rotates_and_flips(matrix_from_pattern(patt))\n",
    "    #for x in xformpatts:\n",
    "    if patt in rules:\n",
    "        return matrix_from_pattern(rules[patt])\n",
    "    print(\"No rule for \" + patt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractal_art(rulelines, startpatt, iters=5):\n",
    "    rules = parse_fractal_rules(rulelines)\n",
    "    A = matrix_from_pattern(startpatt)\n",
    "    for i in range(iters):\n",
    "        #print(i, flush=True)\n",
    "        rows, cols = A.shape\n",
    "        if rows % 2 == 0:\n",
    "            newrows = newcols = rows//2*3\n",
    "            sz = 2\n",
    "        else:\n",
    "            newrows = newcols = rows//3*4\n",
    "            sz = 3\n",
    "        newA = np.full((newrows,newcols), '.')\n",
    "        for r in range(0, rows//sz):\n",
    "            for c in range(0, cols//sz):\n",
    "                inpatt = pattern_from_matrix(A[r*sz:(r+1)*sz, c*sz:(c+1)*sz])\n",
    "                outmatrix = enhancement_matrix(rules, inpatt)\n",
    "                outr, outc = outmatrix.shape\n",
    "                newA[r*outr:(r+1)*outr, c*outc:(c+1)*outc] = outmatrix\n",
    "        A = newA\n",
    "    return np.count_nonzero(A == '#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"../.# => ##./#../...\n",
    ".#./..#/### => #..#/..../..../#..#\"\"\"\n",
    "\n",
    "assert(fractal_art(sample.split('\\n'), '.#./..#/###', 2)) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = Input(21).read().splitlines()\n",
    "fractal_art(real, '.#./..#/###')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying to run Part 2 on my original solution, it was taking too long, so I thought of optimizations. I realized that I didn't have to apply the flip/rotate transformations on the submatrices, I could pre-compute them on the rules themselves. With that implemented, it took about 20 seconds to calculate the answer.\n",
    "\n",
    "For further optimization, I could potentially try not using a string datatype in the `numpy` arrays, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936582"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractal_art(real, '.#./..#/###', 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 22\n",
    "## Part 1\n",
    "> The grid computing cluster is a seemingly-infinite two-dimensional grid of compute nodes. Each node is either **clean** or **infected** by the virus.\n",
    "\n",
    "> exactly one **virus carrier** moves through the network, infecting or cleaning nodes as it moves. The virus carrier is always located on a single node in the network (the **current node**) and keeps track of the **direction** it is facing.\n",
    "\n",
    "> the virus carrier works in bursts; in each burst, it **wakes up**, does some **work**, and goes back to **sleep**. The following steps are all executed **in order** one time each burst:\n",
    "\n",
    "> - If the **current node** is **infected**, it turns to its **right**. Otherwise, it turns to its **left**. (Turning is done in-place; the **current node** does not change.)\n",
    "> - If the **current node** is **clean**, it becomes **infected**. Otherwise, it becomes **cleaned**. (This is done **after** the node is considered for the purposes of changing direction.)\n",
    "> - The virus carrier moves **forward** one node in the direction it is facing.\n",
    "\n",
    "> Diagnostics have also provided a map of the node infection status (your puzzle input). Clean nodes are shown as `.`; infected nodes are shown as `#`. The virus carrier begins in the middle of the map facing **up**.\n",
    "\n",
    "> Given your actual map, after 10000 bursts of activity, how many bursts cause a node to become infected? (Do not count nodes that begin infected.)\n",
    "\n",
    "Modeling an infinite grid could be done with a sparse array implementation, of which scipy has a few. But I'm going to try using a hash whose keys are tuples representing the coordinates as integers. I'll arbitrarily define the centre grid element of the input map as `(0,0)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sporifica(G, bursts=10000):\n",
    "    # 2-dimensional grid, indexed by (i,j) tuples\n",
    "    grid = defaultdict(lambda: '.')\n",
    "    # DIRS: UP, RIGHT, DOWN, LEFT\n",
    "    DIRS = [(0, -1), (1, 0), (0, 1), (-1, 0)]\n",
    "\n",
    "    # Input is an array of strings, representing the input grid\n",
    "    def populate_grid(G):\n",
    "        n = len(G)\n",
    "        assert(n == len(G[0])) # Check square input\n",
    "\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                grid[(i - n//2, j - n//2)] = G[j][i]\n",
    "    \n",
    "    def run(bursts):\n",
    "        dir = 0\n",
    "        burst_infected = 0\n",
    "        cur = (0,0)\n",
    "        dirsize = len(DIRS)\n",
    "        for _ in range(bursts):\n",
    "            if grid[cur] == '#':\n",
    "                dir = (dir + 1) % dirsize\n",
    "                grid[cur] = '.'\n",
    "            else:\n",
    "                dir = (dir - 1) % dirsize\n",
    "                grid[cur] = '#'\n",
    "                burst_infected += 1\n",
    "            cur = (cur[0] + DIRS[dir][0], cur[1] + DIRS[dir][1])\n",
    "        return burst_infected\n",
    "    \n",
    "    populate_grid(G)\n",
    "    return run(bursts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"..#\\n#..\\n...\".split('\\n')\n",
    "assert(sporifica(test, 10000) == 5587)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5433"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sporifica(Input(22).read().splitlines(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "> Now, before it infects a clean node, it will **weaken** it to disable your defenses. If it encounters an infected node, it will instead **flag** the node to be cleaned in the future. So:\n",
    "\n",
    "> - **Clean** nodes become **weakened**.\n",
    "> - **Weakened** nodes become **infected**.\n",
    "> - **Infected** nodes become **flagged**.\n",
    "> - **Flagged** nodes become **clean**.\n",
    "\n",
    "> Every node is always in exactly one of the above states.\n",
    "\n",
    "> the following logic during its bursts of action:\n",
    "\n",
    "> - Decide which way to turn based on the current node:\n",
    ">     - If it is clean, it turns left.\n",
    ">     - If it is weakened, it does not turn, and will continue moving in the same direction.\n",
    ">     - If it is infected, it turns right.\n",
    ">     - If it is flagged, it reverses direction, and will go back the way it came.\n",
    "> - Modify the state of the current node, as described above.\n",
    "> - The virus carrier moves forward one node in the direction it is facing.\n",
    "\n",
    "> the same initial state as the previous example, and drawing weakened as W and flagged as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sporifica2(G, bursts=10000):\n",
    "    # 2-dimensional grid, indexed by (i,j) tuples\n",
    "    grid = defaultdict(lambda: '.')\n",
    "    # DIRS: UP, RIGHT, DOWN, LEFT\n",
    "    DIRS = [(0, -1), (1, 0), (0, 1), (-1, 0)]\n",
    "\n",
    "    # Input is an array of strings, representing the input grid\n",
    "    def populate_grid(G):\n",
    "        n = len(G)\n",
    "        assert(n == len(G[0])) # Check square input\n",
    "\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                grid[(i - n//2, j - n//2)] = G[j][i]\n",
    "    \n",
    "    def run(bursts):\n",
    "        dir = 0\n",
    "        burst_infected = 0\n",
    "        cur = (0,0)\n",
    "        dirsize = len(DIRS)\n",
    "        for _ in range(bursts):\n",
    "            x = grid[cur]\n",
    "            if x == '.': # clean\n",
    "                dir = (dir - 1) % dirsize\n",
    "                grid[cur] = 'W'\n",
    "            elif x == 'W': # weakened\n",
    "                grid[cur] = '#'\n",
    "                burst_infected += 1\n",
    "            elif x == '#': # infected\n",
    "                dir = (dir + 1) % dirsize\n",
    "                grid[cur] = 'F'\n",
    "            elif x == 'F': # flagged\n",
    "                dir = (dir + 2) % dirsize\n",
    "                grid[cur] = '.'\n",
    "\n",
    "            cur = (cur[0] + DIRS[dir][0], cur[1] + DIRS[dir][1])\n",
    "\n",
    "        return burst_infected\n",
    "    \n",
    "    populate_grid(G)\n",
    "    return run(bursts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"..#\\n#..\\n...\".split('\\n')\n",
    "assert(sporifica2(test, 100) == 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2512599"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sporifica2(Input(22).read().splitlines(), 10_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 23\n",
    "## Part 1\n",
    "> The code it's running seems to be a variant of the kind you saw recently on that tablet. The general functionality seems very similar, but some of the instructions are different:\n",
    "\n",
    "> - `set X Y` sets register X to the value of Y.\n",
    "> - `sub X Y` decreases register X by the value of Y.\n",
    "> - `mul X Y` sets register X to the result of multiplying the value contained in register X by the value of Y.\n",
    "> - `jnz X Y` jumps with an offset of the value of Y, but only if the value of X is not zero. (An offset of 2 skips the next instruction, an offset of -1 jumps to the previous instruction, and so on.)\n",
    "\n",
    "> Only the instructions listed above are used. The eight registers here, named a through h, all start at 0.\n",
    "\n",
    "> how many times is the mul instruction invoked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conflagration:\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        self.regs = defaultdict(lambda: 0)\n",
    "        self.char_re = re.compile(\"[a-z]\")\n",
    "        self.mul_exe = 0\n",
    "    \n",
    "    def get_assembly_value(self, arg):\n",
    "        \"Given an assembly value, return the register value, if the argument is a register; otherwise, the value itself.\"\n",
    "        if self.char_re.fullmatch(arg):\n",
    "            return self.regs[arg]\n",
    "        else:\n",
    "            return int(arg)\n",
    "\n",
    "    def run(self):\n",
    "        next_line = 0\n",
    "        while next_line in range(0, len(self.lines)):\n",
    "            next_line = self.execute_line(next_line)\n",
    "        print(\"mul call count: %d\" % self.mul_exe)\n",
    "            \n",
    "    def execute_line(self, line_index):\n",
    "        offset = 1\n",
    "        line = self.lines[line_index]\n",
    "        if line[0:3] == 'set':\n",
    "            reg, arg = re.match(r\"set (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] = val\n",
    "        elif line[0:3] == 'sub':\n",
    "            reg, arg = re.match(r\"sub (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] -= val\n",
    "        elif line[0:3] == 'mul':\n",
    "            reg, arg = re.match(r\"mul (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            self.regs[reg] *= val\n",
    "            self.mul_exe += 1\n",
    "        elif line[0:3] == 'jnz':\n",
    "            X, arg = re.match(r\"jnz (.) (.+)\", line).groups()\n",
    "            val = self.get_assembly_value(arg)\n",
    "            check = self.get_assembly_value(X)\n",
    "            if check != 0:\n",
    "                offset = val\n",
    "        \n",
    "        return line_index + offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul call count: 3969\n"
     ]
    }
   ],
   "source": [
    "prog = Input(23).read().splitlines()\n",
    "Conflagration(prog).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
